{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python for Data Science Project Session 5: Economics and Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this session, we will look at two mini projects related to Economics/Finance, applying techniques covered in Session Five and extending these a bit further. To start, we will import our general data science packages here, and then add the necessary machine learning imports as we go along so that it's clear when to use what: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing key data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convergence warning disabling\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mini-Projects\n",
    "> [Classification: Which companies go bust?](#Classification:-Which-companies-go-bust?)\n",
    ">\n",
    "> [Regression: What are the drivers of worker productivity?](#Regression:-What-are-the-drivers-of-worker-productivity?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification: Which companies go bust?\n",
    "For this project, we will aim to predict if a company is likely to go bankrupt given a variety of accounting and financial metrics. To do this, we will use  data collected from the Taiwan Economic Journal for the years 1999 to 2009. This kind of model would have all sorts of real world applications, from portfolio stock picks to loan approvals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start out, lets get an overview of our data set dimensions and feature types. We'll be doing a very simple overview in this section but feel free to perform more extensive EDA on your own: the more you know about your data, the better you can harness it through modelling.\n",
    "\n",
    "Start out with the following tasks:\n",
    "- Read in the data set as a pandas DataFrame (file path: `data/bankruptcy.csv`)\n",
    "- Output the first five data set rows\n",
    "- Print out a comprehensive summary of the data set (dimensions, variable names, data types, and null values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read bankruptcy data set\n",
    "bankruptcy=pd.read_csv(\"bankruptcy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bankrupt</th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>Operating Gross Margin</th>\n",
       "      <th>Realized Sales Gross Margin</th>\n",
       "      <th>Operating Profit Rate</th>\n",
       "      <th>Pre-tax net Interest Rate</th>\n",
       "      <th>After-tax net Interest Rate</th>\n",
       "      <th>Non-industry income and expenditure/revenue</th>\n",
       "      <th>...</th>\n",
       "      <th>Net Income to Total Assets</th>\n",
       "      <th>Total assets to GNP price</th>\n",
       "      <th>No-credit Interval</th>\n",
       "      <th>Gross Profit to Sales</th>\n",
       "      <th>Net Income to Stockholder's Equity</th>\n",
       "      <th>Liability to Equity</th>\n",
       "      <th>Degree of Financial Leverage (DFL)</th>\n",
       "      <th>Interest Coverage Ratio (Interest expense to EBIT)</th>\n",
       "      <th>Net Income Flag</th>\n",
       "      <th>Equity to Liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Bankrupt   ROA(C) before interest and depreciation before interest  \\\n",
       "0         1                                           0.370594          \n",
       "1         1                                           0.464291          \n",
       "2         1                                           0.426071          \n",
       "3         1                                           0.399844          \n",
       "4         1                                           0.465022          \n",
       "\n",
       "    ROA(A) before interest and % after tax  \\\n",
       "0                                 0.424389   \n",
       "1                                 0.538214   \n",
       "2                                 0.499019   \n",
       "3                                 0.451265   \n",
       "4                                 0.538432   \n",
       "\n",
       "    ROA(B) before interest and depreciation after tax  \\\n",
       "0                                           0.405750    \n",
       "1                                           0.516730    \n",
       "2                                           0.472295    \n",
       "3                                           0.457733    \n",
       "4                                           0.522298    \n",
       "\n",
       "    Operating Gross Margin   Realized Sales Gross Margin  \\\n",
       "0                 0.601457                      0.601457   \n",
       "1                 0.610235                      0.610235   \n",
       "2                 0.601450                      0.601364   \n",
       "3                 0.583541                      0.583541   \n",
       "4                 0.598783                      0.598783   \n",
       "\n",
       "    Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
       "0                0.998969                    0.796887   \n",
       "1                0.998946                    0.797380   \n",
       "2                0.998857                    0.796403   \n",
       "3                0.998700                    0.796967   \n",
       "4                0.998973                    0.797366   \n",
       "\n",
       "    After-tax net Interest Rate   Non-industry income and expenditure/revenue  \\\n",
       "0                      0.808809                                      0.302646   \n",
       "1                      0.809301                                      0.303556   \n",
       "2                      0.808388                                      0.302035   \n",
       "3                      0.808966                                      0.303350   \n",
       "4                      0.809304                                      0.303475   \n",
       "\n",
       "   ...   Net Income to Total Assets   Total assets to GNP price  \\\n",
       "0  ...                     0.716845                    0.009219   \n",
       "1  ...                     0.795297                    0.008323   \n",
       "2  ...                     0.774670                    0.040003   \n",
       "3  ...                     0.739555                    0.003252   \n",
       "4  ...                     0.795016                    0.003878   \n",
       "\n",
       "    No-credit Interval   Gross Profit to Sales  \\\n",
       "0             0.622879                0.601453   \n",
       "1             0.623652                0.610237   \n",
       "2             0.623841                0.601449   \n",
       "3             0.622929                0.583538   \n",
       "4             0.623521                0.598782   \n",
       "\n",
       "    Net Income to Stockholder's Equity   Liability to Equity  \\\n",
       "0                             0.827890              0.290202   \n",
       "1                             0.839969              0.283846   \n",
       "2                             0.836774              0.290189   \n",
       "3                             0.834697              0.281721   \n",
       "4                             0.839973              0.278514   \n",
       "\n",
       "    Degree of Financial Leverage (DFL)  \\\n",
       "0                             0.026601   \n",
       "1                             0.264577   \n",
       "2                             0.026555   \n",
       "3                             0.026697   \n",
       "4                             0.024752   \n",
       "\n",
       "    Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
       "0                                           0.564050                   1   \n",
       "1                                           0.570175                   1   \n",
       "2                                           0.563706                   1   \n",
       "3                                           0.564663                   1   \n",
       "4                                           0.575617                   1   \n",
       "\n",
       "    Equity to Liability  \n",
       "0              0.016469  \n",
       "1              0.020794  \n",
       "2              0.016474  \n",
       "3              0.023982  \n",
       "4              0.035490  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the first five rows\n",
    "bankruptcy.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6819, 96) Index(['Bankrupt', ' ROA(C) before interest and depreciation before interest',\n",
      "       ' ROA(A) before interest and % after tax',\n",
      "       ' ROA(B) before interest and depreciation after tax',\n",
      "       ' Operating Gross Margin', ' Realized Sales Gross Margin',\n",
      "       ' Operating Profit Rate', ' Pre-tax net Interest Rate',\n",
      "       ' After-tax net Interest Rate',\n",
      "       ' Non-industry income and expenditure/revenue',\n",
      "       ' Continuous interest rate (after tax)', ' Operating Expense Rate',\n",
      "       ' Research and development expense rate', ' Cash flow rate',\n",
      "       ' Interest-bearing debt interest rate', ' Tax rate (A)',\n",
      "       ' Net Value Per Share (B)', ' Net Value Per Share (A)',\n",
      "       ' Net Value Per Share (C)', ' Persistent EPS in the Last Four Seasons',\n",
      "       ' Cash Flow Per Share', ' Revenue Per Share (Yuan Â¥)',\n",
      "       ' Operating Profit Per Share (Yuan Â¥)',\n",
      "       ' Per Share Net profit before tax (Yuan Â¥)',\n",
      "       ' Realized Sales Gross Profit Growth Rate',\n",
      "       ' Operating Profit Growth Rate', ' After-tax Net Profit Growth Rate',\n",
      "       ' Regular Net Profit Growth Rate', ' Continuous Net Profit Growth Rate',\n",
      "       ' Total Asset Growth Rate', ' Net Value Growth Rate',\n",
      "       ' Total Asset Return Growth Rate Ratio', ' Cash Reinvestment %',\n",
      "       ' Current Ratio', ' Quick Ratio', ' Interest Expense Ratio',\n",
      "       ' Total debt/Total net worth', ' Debt ratio %', ' Net worth/Assets',\n",
      "       ' Long-term fund suitability ratio (A)', ' Borrowing dependency',\n",
      "       ' Contingent liabilities/Net worth',\n",
      "       ' Operating profit/Paid-in capital',\n",
      "       ' Net profit before tax/Paid-in capital',\n",
      "       ' Inventory and accounts receivable/Net value', ' Total Asset Turnover',\n",
      "       ' Accounts Receivable Turnover', ' Average Collection Days',\n",
      "       ' Inventory Turnover Rate (times)', ' Fixed Assets Turnover Frequency',\n",
      "       ' Net Worth Turnover Rate (times)', ' Revenue per person',\n",
      "       ' Operating profit per person', ' Allocation rate per person',\n",
      "       ' Working Capital to Total Assets', ' Quick Assets/Total Assets',\n",
      "       ' Current Assets/Total Assets', ' Cash/Total Assets',\n",
      "       ' Quick Assets/Current Liability', ' Cash/Current Liability',\n",
      "       ' Current Liability to Assets', ' Operating Funds to Liability',\n",
      "       ' Inventory/Working Capital', ' Inventory/Current Liability',\n",
      "       ' Current Liabilities/Liability', ' Working Capital/Equity',\n",
      "       ' Current Liabilities/Equity', ' Long-term Liability to Current Assets',\n",
      "       ' Retained Earnings to Total Assets', ' Total income/Total expense',\n",
      "       ' Total expense/Assets', ' Current Asset Turnover Rate',\n",
      "       ' Quick Asset Turnover Rate', ' Working capitcal Turnover Rate',\n",
      "       ' Cash Turnover Rate', ' Cash Flow to Sales', ' Fixed Assets to Assets',\n",
      "       ' Current Liability to Liability', ' Current Liability to Equity',\n",
      "       ' Equity to Long-term Liability', ' Cash Flow to Total Assets',\n",
      "       ' Cash Flow to Liability', ' CFO to Assets', ' Cash Flow to Equity',\n",
      "       ' Current Liability to Current Assets', ' Liability-Assets Flag',\n",
      "       ' Net Income to Total Assets', ' Total assets to GNP price',\n",
      "       ' No-credit Interval', ' Gross Profit to Sales',\n",
      "       ' Net Income to Stockholder's Equity', ' Liability to Equity',\n",
      "       ' Degree of Financial Leverage (DFL)',\n",
      "       ' Interest Coverage Ratio (Interest expense to EBIT)',\n",
      "       ' Net Income Flag', ' Equity to Liability'],\n",
      "      dtype='object') Bankrupt                                                      int64\n",
      " ROA(C) before interest and depreciation before interest    float64\n",
      " ROA(A) before interest and % after tax                     float64\n",
      " ROA(B) before interest and depreciation after tax          float64\n",
      " Operating Gross Margin                                     float64\n",
      "                                                             ...   \n",
      " Liability to Equity                                        float64\n",
      " Degree of Financial Leverage (DFL)                         float64\n",
      " Interest Coverage Ratio (Interest expense to EBIT)         float64\n",
      " Net Income Flag                                              int64\n",
      " Equity to Liability                                        float64\n",
      "Length: 96, dtype: object Bankrupt                                                    0\n",
      " ROA(C) before interest and depreciation before interest    0\n",
      " ROA(A) before interest and % after tax                     0\n",
      " ROA(B) before interest and depreciation after tax          0\n",
      " Operating Gross Margin                                     0\n",
      "                                                           ..\n",
      " Liability to Equity                                        0\n",
      " Degree of Financial Leverage (DFL)                         0\n",
      " Interest Coverage Ratio (Interest expense to EBIT)         0\n",
      " Net Income Flag                                            0\n",
      " Equity to Liability                                        0\n",
      "Length: 96, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print the data set overview (dimensions, variable names, data types, null values)\n",
    "dim = bankruptcy.shape\n",
    "cols = bankruptcy.columns\n",
    "dtypes = bankruptcy.dtypes\n",
    "nulls = bankruptcy.isna().sum()\n",
    "print(dim,cols,dtypes,nulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our ML setup\n",
    "To start our project we want to set up our data in the usual machine learning configuration: a training and a test set, each with its own feature matrix and target vector. To start:\n",
    "\n",
    "- Import the `train_test_split()` function from scikit learn\n",
    "- Declare a target vector y (corresponding to the `Bankrupt` column in the data set)\n",
    "- Declare a feature matrix X (including all columns except `Bankrupt`)\n",
    "- Create a training and test set\n",
    "- Print the dimensions of X and y in both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train-test split function\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the target vector y which has the column label 'Bankrupt'\n",
    "y=bankruptcy.loc[:,'Bankrupt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROA(C) before interest and depreciation before interest</th>\n",
       "      <th>ROA(A) before interest and % after tax</th>\n",
       "      <th>ROA(B) before interest and depreciation after tax</th>\n",
       "      <th>Operating Gross Margin</th>\n",
       "      <th>Realized Sales Gross Margin</th>\n",
       "      <th>Operating Profit Rate</th>\n",
       "      <th>Pre-tax net Interest Rate</th>\n",
       "      <th>After-tax net Interest Rate</th>\n",
       "      <th>Non-industry income and expenditure/revenue</th>\n",
       "      <th>Continuous interest rate (after tax)</th>\n",
       "      <th>...</th>\n",
       "      <th>Net Income to Total Assets</th>\n",
       "      <th>Total assets to GNP price</th>\n",
       "      <th>No-credit Interval</th>\n",
       "      <th>Gross Profit to Sales</th>\n",
       "      <th>Net Income to Stockholder's Equity</th>\n",
       "      <th>Liability to Equity</th>\n",
       "      <th>Degree of Financial Leverage (DFL)</th>\n",
       "      <th>Interest Coverage Ratio (Interest expense to EBIT)</th>\n",
       "      <th>Net Income Flag</th>\n",
       "      <th>Equity to Liability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.370594</td>\n",
       "      <td>0.424389</td>\n",
       "      <td>0.405750</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.601457</td>\n",
       "      <td>0.998969</td>\n",
       "      <td>0.796887</td>\n",
       "      <td>0.808809</td>\n",
       "      <td>0.302646</td>\n",
       "      <td>0.780985</td>\n",
       "      <td>...</td>\n",
       "      <td>0.716845</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.622879</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.827890</td>\n",
       "      <td>0.290202</td>\n",
       "      <td>0.026601</td>\n",
       "      <td>0.564050</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.464291</td>\n",
       "      <td>0.538214</td>\n",
       "      <td>0.516730</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.610235</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.797380</td>\n",
       "      <td>0.809301</td>\n",
       "      <td>0.303556</td>\n",
       "      <td>0.781506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795297</td>\n",
       "      <td>0.008323</td>\n",
       "      <td>0.623652</td>\n",
       "      <td>0.610237</td>\n",
       "      <td>0.839969</td>\n",
       "      <td>0.283846</td>\n",
       "      <td>0.264577</td>\n",
       "      <td>0.570175</td>\n",
       "      <td>1</td>\n",
       "      <td>0.020794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.426071</td>\n",
       "      <td>0.499019</td>\n",
       "      <td>0.472295</td>\n",
       "      <td>0.601450</td>\n",
       "      <td>0.601364</td>\n",
       "      <td>0.998857</td>\n",
       "      <td>0.796403</td>\n",
       "      <td>0.808388</td>\n",
       "      <td>0.302035</td>\n",
       "      <td>0.780284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.774670</td>\n",
       "      <td>0.040003</td>\n",
       "      <td>0.623841</td>\n",
       "      <td>0.601449</td>\n",
       "      <td>0.836774</td>\n",
       "      <td>0.290189</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.563706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.399844</td>\n",
       "      <td>0.451265</td>\n",
       "      <td>0.457733</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.583541</td>\n",
       "      <td>0.998700</td>\n",
       "      <td>0.796967</td>\n",
       "      <td>0.808966</td>\n",
       "      <td>0.303350</td>\n",
       "      <td>0.781241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.739555</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.622929</td>\n",
       "      <td>0.583538</td>\n",
       "      <td>0.834697</td>\n",
       "      <td>0.281721</td>\n",
       "      <td>0.026697</td>\n",
       "      <td>0.564663</td>\n",
       "      <td>1</td>\n",
       "      <td>0.023982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.465022</td>\n",
       "      <td>0.538432</td>\n",
       "      <td>0.522298</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.598783</td>\n",
       "      <td>0.998973</td>\n",
       "      <td>0.797366</td>\n",
       "      <td>0.809304</td>\n",
       "      <td>0.303475</td>\n",
       "      <td>0.781550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.795016</td>\n",
       "      <td>0.003878</td>\n",
       "      <td>0.623521</td>\n",
       "      <td>0.598782</td>\n",
       "      <td>0.839973</td>\n",
       "      <td>0.278514</td>\n",
       "      <td>0.024752</td>\n",
       "      <td>0.575617</td>\n",
       "      <td>1</td>\n",
       "      <td>0.035490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6814</th>\n",
       "      <td>0.493687</td>\n",
       "      <td>0.539468</td>\n",
       "      <td>0.543230</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.604462</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797409</td>\n",
       "      <td>0.809331</td>\n",
       "      <td>0.303510</td>\n",
       "      <td>0.781588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.623620</td>\n",
       "      <td>0.604455</td>\n",
       "      <td>0.840359</td>\n",
       "      <td>0.279606</td>\n",
       "      <td>0.027064</td>\n",
       "      <td>0.566193</td>\n",
       "      <td>1</td>\n",
       "      <td>0.029890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6815</th>\n",
       "      <td>0.475162</td>\n",
       "      <td>0.538269</td>\n",
       "      <td>0.524172</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.598308</td>\n",
       "      <td>0.998992</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.809327</td>\n",
       "      <td>0.303520</td>\n",
       "      <td>0.781586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799748</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.623931</td>\n",
       "      <td>0.598306</td>\n",
       "      <td>0.840306</td>\n",
       "      <td>0.278132</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.566018</td>\n",
       "      <td>1</td>\n",
       "      <td>0.038284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6816</th>\n",
       "      <td>0.472725</td>\n",
       "      <td>0.533744</td>\n",
       "      <td>0.520638</td>\n",
       "      <td>0.610444</td>\n",
       "      <td>0.610213</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>0.797401</td>\n",
       "      <td>0.809317</td>\n",
       "      <td>0.303512</td>\n",
       "      <td>0.781546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797778</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.624156</td>\n",
       "      <td>0.610441</td>\n",
       "      <td>0.840138</td>\n",
       "      <td>0.275789</td>\n",
       "      <td>0.026791</td>\n",
       "      <td>0.565158</td>\n",
       "      <td>1</td>\n",
       "      <td>0.097649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6817</th>\n",
       "      <td>0.506264</td>\n",
       "      <td>0.559911</td>\n",
       "      <td>0.554045</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.607850</td>\n",
       "      <td>0.999074</td>\n",
       "      <td>0.797500</td>\n",
       "      <td>0.809399</td>\n",
       "      <td>0.303498</td>\n",
       "      <td>0.781663</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811808</td>\n",
       "      <td>0.002837</td>\n",
       "      <td>0.623957</td>\n",
       "      <td>0.607846</td>\n",
       "      <td>0.841084</td>\n",
       "      <td>0.277547</td>\n",
       "      <td>0.026822</td>\n",
       "      <td>0.565302</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6818</th>\n",
       "      <td>0.493053</td>\n",
       "      <td>0.570105</td>\n",
       "      <td>0.549548</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.627409</td>\n",
       "      <td>0.998080</td>\n",
       "      <td>0.801987</td>\n",
       "      <td>0.813800</td>\n",
       "      <td>0.313415</td>\n",
       "      <td>0.786079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815956</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.626680</td>\n",
       "      <td>0.627408</td>\n",
       "      <td>0.841019</td>\n",
       "      <td>0.275114</td>\n",
       "      <td>0.026793</td>\n",
       "      <td>0.565167</td>\n",
       "      <td>1</td>\n",
       "      <td>0.233902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6819 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ROA(C) before interest and depreciation before interest  \\\n",
       "0                                              0.370594          \n",
       "1                                              0.464291          \n",
       "2                                              0.426071          \n",
       "3                                              0.399844          \n",
       "4                                              0.465022          \n",
       "...                                                 ...          \n",
       "6814                                           0.493687          \n",
       "6815                                           0.475162          \n",
       "6816                                           0.472725          \n",
       "6817                                           0.506264          \n",
       "6818                                           0.493053          \n",
       "\n",
       "       ROA(A) before interest and % after tax  \\\n",
       "0                                    0.424389   \n",
       "1                                    0.538214   \n",
       "2                                    0.499019   \n",
       "3                                    0.451265   \n",
       "4                                    0.538432   \n",
       "...                                       ...   \n",
       "6814                                 0.539468   \n",
       "6815                                 0.538269   \n",
       "6816                                 0.533744   \n",
       "6817                                 0.559911   \n",
       "6818                                 0.570105   \n",
       "\n",
       "       ROA(B) before interest and depreciation after tax  \\\n",
       "0                                              0.405750    \n",
       "1                                              0.516730    \n",
       "2                                              0.472295    \n",
       "3                                              0.457733    \n",
       "4                                              0.522298    \n",
       "...                                                 ...    \n",
       "6814                                           0.543230    \n",
       "6815                                           0.524172    \n",
       "6816                                           0.520638    \n",
       "6817                                           0.554045    \n",
       "6818                                           0.549548    \n",
       "\n",
       "       Operating Gross Margin   Realized Sales Gross Margin  \\\n",
       "0                    0.601457                      0.601457   \n",
       "1                    0.610235                      0.610235   \n",
       "2                    0.601450                      0.601364   \n",
       "3                    0.583541                      0.583541   \n",
       "4                    0.598783                      0.598783   \n",
       "...                       ...                           ...   \n",
       "6814                 0.604455                      0.604462   \n",
       "6815                 0.598308                      0.598308   \n",
       "6816                 0.610444                      0.610213   \n",
       "6817                 0.607850                      0.607850   \n",
       "6818                 0.627409                      0.627409   \n",
       "\n",
       "       Operating Profit Rate   Pre-tax net Interest Rate  \\\n",
       "0                   0.998969                    0.796887   \n",
       "1                   0.998946                    0.797380   \n",
       "2                   0.998857                    0.796403   \n",
       "3                   0.998700                    0.796967   \n",
       "4                   0.998973                    0.797366   \n",
       "...                      ...                         ...   \n",
       "6814                0.998992                    0.797409   \n",
       "6815                0.998992                    0.797414   \n",
       "6816                0.998984                    0.797401   \n",
       "6817                0.999074                    0.797500   \n",
       "6818                0.998080                    0.801987   \n",
       "\n",
       "       After-tax net Interest Rate  \\\n",
       "0                         0.808809   \n",
       "1                         0.809301   \n",
       "2                         0.808388   \n",
       "3                         0.808966   \n",
       "4                         0.809304   \n",
       "...                            ...   \n",
       "6814                      0.809331   \n",
       "6815                      0.809327   \n",
       "6816                      0.809317   \n",
       "6817                      0.809399   \n",
       "6818                      0.813800   \n",
       "\n",
       "       Non-industry income and expenditure/revenue  \\\n",
       "0                                         0.302646   \n",
       "1                                         0.303556   \n",
       "2                                         0.302035   \n",
       "3                                         0.303350   \n",
       "4                                         0.303475   \n",
       "...                                            ...   \n",
       "6814                                      0.303510   \n",
       "6815                                      0.303520   \n",
       "6816                                      0.303512   \n",
       "6817                                      0.303498   \n",
       "6818                                      0.313415   \n",
       "\n",
       "       Continuous interest rate (after tax)  ...   Net Income to Total Assets  \\\n",
       "0                                  0.780985  ...                     0.716845   \n",
       "1                                  0.781506  ...                     0.795297   \n",
       "2                                  0.780284  ...                     0.774670   \n",
       "3                                  0.781241  ...                     0.739555   \n",
       "4                                  0.781550  ...                     0.795016   \n",
       "...                                     ...  ...                          ...   \n",
       "6814                               0.781588  ...                     0.799927   \n",
       "6815                               0.781586  ...                     0.799748   \n",
       "6816                               0.781546  ...                     0.797778   \n",
       "6817                               0.781663  ...                     0.811808   \n",
       "6818                               0.786079  ...                     0.815956   \n",
       "\n",
       "       Total assets to GNP price   No-credit Interval   Gross Profit to Sales  \\\n",
       "0                       0.009219             0.622879                0.601453   \n",
       "1                       0.008323             0.623652                0.610237   \n",
       "2                       0.040003             0.623841                0.601449   \n",
       "3                       0.003252             0.622929                0.583538   \n",
       "4                       0.003878             0.623521                0.598782   \n",
       "...                          ...                  ...                     ...   \n",
       "6814                    0.000466             0.623620                0.604455   \n",
       "6815                    0.001959             0.623931                0.598306   \n",
       "6816                    0.002840             0.624156                0.610441   \n",
       "6817                    0.002837             0.623957                0.607846   \n",
       "6818                    0.000707             0.626680                0.627408   \n",
       "\n",
       "       Net Income to Stockholder's Equity   Liability to Equity  \\\n",
       "0                                0.827890              0.290202   \n",
       "1                                0.839969              0.283846   \n",
       "2                                0.836774              0.290189   \n",
       "3                                0.834697              0.281721   \n",
       "4                                0.839973              0.278514   \n",
       "...                                   ...                   ...   \n",
       "6814                             0.840359              0.279606   \n",
       "6815                             0.840306              0.278132   \n",
       "6816                             0.840138              0.275789   \n",
       "6817                             0.841084              0.277547   \n",
       "6818                             0.841019              0.275114   \n",
       "\n",
       "       Degree of Financial Leverage (DFL)  \\\n",
       "0                                0.026601   \n",
       "1                                0.264577   \n",
       "2                                0.026555   \n",
       "3                                0.026697   \n",
       "4                                0.024752   \n",
       "...                                   ...   \n",
       "6814                             0.027064   \n",
       "6815                             0.027009   \n",
       "6816                             0.026791   \n",
       "6817                             0.026822   \n",
       "6818                             0.026793   \n",
       "\n",
       "       Interest Coverage Ratio (Interest expense to EBIT)   Net Income Flag  \\\n",
       "0                                              0.564050                   1   \n",
       "1                                              0.570175                   1   \n",
       "2                                              0.563706                   1   \n",
       "3                                              0.564663                   1   \n",
       "4                                              0.575617                   1   \n",
       "...                                                 ...                 ...   \n",
       "6814                                           0.566193                   1   \n",
       "6815                                           0.566018                   1   \n",
       "6816                                           0.565158                   1   \n",
       "6817                                           0.565302                   1   \n",
       "6818                                           0.565167                   1   \n",
       "\n",
       "       Equity to Liability  \n",
       "0                 0.016469  \n",
       "1                 0.020794  \n",
       "2                 0.016474  \n",
       "3                 0.023982  \n",
       "4                 0.035490  \n",
       "...                    ...  \n",
       "6814              0.029890  \n",
       "6815              0.038284  \n",
       "6816              0.097649  \n",
       "6817              0.044009  \n",
       "6818              0.233902  \n",
       "\n",
       "[6819 rows x 95 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declare feature matrix\n",
    "X=bankruptcy.drop('Bankrupt',axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train-test- split using random state 253, test_size 30%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=253\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimensions:  (4773, 95)\n",
      "y_train dimensions:  (4773,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train dimensions: ', X_train.shape)\n",
    "print('y_train dimensions: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test dimensions:  (2046, 95)\n",
      "y_test dimensions:  (2046,)\n"
     ]
    }
   ],
   "source": [
    "print('X_test dimensions: ', X_test.shape)\n",
    "print('y_test dimensions: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem that is immediately apparent is that we have a high number of features in our data. This constitutes a problem as capturing the complexities of a highly dimensional space through our model can lead us to **overfitting**. \n",
    "> This is known as the [Curse of Dimensionality](https://en.wikipedia.org/wiki/Curse_of_dimensionality#Machine_Learning) and is definitely a topic worth exploring further.\n",
    "\n",
    "\n",
    "In order to cope with the high dimensionality of our data we can employ several dimensionality reduction techniques. The first one we'll explore is called **Principal Component Analysis (PCA)** and for a more in-depth treatment of the subject be sure to refer [here](https://towardsdatascience.com/a-one-stop-shop-for-principal-component-analysis-5582fb7e0a9c). PCA essentially works by projecting our data points (which can be seen as vectors) into a lower dimensional space while maximizing the conserved variance of our data.\n",
    "\n",
    "Try out PCA on the training feature matrix `X_train` below:\n",
    "- Import the `PCA` class from the `sklearn.decomposition` module.\n",
    "- Decide on a number for `n_components`. This is going to be the new number of features.\n",
    "- Create a PCA transformer.\n",
    "- Train the transformer using the `.fit()` method.\n",
    "- Apply dimensionality reduction using the `.transform()` method.\n",
    "- Output the first five rows.\n",
    "\n",
    "> **Note:** The `.tranfrom()` method will return a NumPy array as opposed to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing PCA class\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA transformer that keeps 30 components \n",
    "n_components = 30\n",
    "pca = PCA(n_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(n_components=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(n_components=30)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and transform using our PCA model\n",
    "pca.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might've noticed that most machine learning with scikit learn involves:\n",
    "- Instantiating a transformer or model.\n",
    "- Fitting this to our data using `.fit()`.\n",
    "- Transforming or predicting using `.transform()` or `.predict()`.\n",
    "\n",
    "This simple, general process means that we can simplify our ML process using **Pipelines**. A Pipeline allows you to establish a sequence of transformations terminating with *one estimator*. Pipelines can then be treated as any other scikit learn estimator, but each time they perform all of the interim transformation steps in the sequence. This has the benefit of greatly simplifying your code and can also help prevent [data leakage](https://machinelearningmastery.com/data-leakage-machine-learning/). \n",
    "\n",
    "To instantiate a Pipeline you must pass as an argument a list of $n+1$ tuples (where $n$ is the number of transforms) in the form: `[('transformer_1_name', transformer_1), ..., ('estimator_name', estimator)]`.\n",
    "\n",
    "We will now create Pipelines for a KNN, SVM, and Logistic Regression model below:\n",
    "- Import the `StandardScaler`, `KNeighborsClassifier`, `SVC`, and `LogisticRegression` classes from scikit learn.\n",
    "- Import the `Pipeline` class from scikit learn.\n",
    "- For each one of the three models, create a Pipeline with the following transforms (in order): scaling, PCA, estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KNN, SVM, and Logistic Regression models \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these into three Pipelines, one for each model\n",
    "knn_pipe = Pipeline([('Scaler', StandardScaler()), \n",
    "                     ('PCA', PCA(n_components=30)), \n",
    "                     ('Model', KNeighborsClassifier())])\n",
    "SVC_pipe = Pipeline([('Scaler', StandardScaler()), \n",
    "                     ('PCA', PCA(n_components=30)), \n",
    "                     ('Model', SVC())])\n",
    "logit_pipe = Pipeline([('Scaler', StandardScaler()), \n",
    "                     ('PCA', PCA(n_components=30)), \n",
    "                     ('Model', LogisticRegression())])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During Session Five, you were introduced to Accuracy as an evaluation metric for classification model. As a reminder, accuracy is defined as follows:\n",
    "$$ \\text{Accuracy} = \\frac{TP+TN}{TP+FP+TN+FN}$$\n",
    "In other words, it is the ratio of correctly classified samples to the overall number of samples. We're now gonna compute accuracy for our three models. To do this, we use the `cross_val_score()` function from scikit learn (for documentation, see [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html?highlight=cross_val_score#sklearn.model_selection.cross_val_score)). This function calculates the average score (taking accuracy as the default metric for classification models) after carrying out K-fold cross validation, which we prefer in order to reduce bias and thus get a more 'realistic' estimate of our model's performance. \n",
    "\n",
    "To start out, print the average accuracy score for each of our models:\n",
    "- Import the `cross_val_score()` function from scikit learn.\n",
    "- Calculate the cross-validated scores for each pipeline estimator.\n",
    "- Print the mean score for each pipeline estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing cross_val_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating mean cross-validated scores\n",
    "knn_score = cross_val_score(knn_pipe, X_train, y_train).mean()\n",
    "SVC_score = cross_val_score(SVC_pipe, X_train, y_train).mean()\n",
    "logit_score = cross_val_score(logit_pipe, X_train, y_train).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score:\n",
      "0.964382978256336\n"
     ]
    }
   ],
   "source": [
    "print('KNN Accuracy Score:')\n",
    "print(knn_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score:\n",
      "0.9677348612071521\n"
     ]
    }
   ],
   "source": [
    "print('SVM Accuracy Score:')\n",
    "print(SVC_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy Score:\n",
      "0.9656395227589538\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression Accuracy Score:')\n",
    "print(logit_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although accuracy is a good starting point to illustrate our model's predictive performance, it does come with some caveats. This is perhaps better illustrated by an example:\n",
    "\n",
    ">**Example:**\n",
    ">\n",
    "> *Imagine if I told you I can build a machine learning model that predicts whether or not an applicant is admitted into Harvard with 96.4% accuracy. Sounds good right! Now what if I told you the model works by predicting `NOT_ACCEPTED` to every applicant, irrespective of any data observed. This works as Harvard has a 4.6% admissions rate, but is our model any good?*  \n",
    "\n",
    "Often, we must consider using other metrics in classification. The best way to start out is by analysing how true positives/negatives are distributed among classes. We can do this through a confusion matrix, which represents this distribution in the following form:\n",
    "\n",
    "\n",
    "<img src='https://miro.medium.com/max/2102/1*fxiTNIgOyvAombPJx5KGeA.png' width=\"450\" height=\"400\">\n",
    "\n",
    "\n",
    "To output the confusion matrix of our predictions, we use the `confusion_matrix()` function from scikit learn (for documentation, see [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html?highlight=confusion#sklearn.metrics.confusion_matrix)). Try outputting the confussion matrix for all three of our model predictions:\n",
    "\n",
    "- Import the `confusion_matrix()` function from scikit learn.\n",
    "- Further separate the training set into training and validation sets using `train_test_split()` (suggested`test_size=0.2`).\n",
    "- Fit all pipeline estimators on the training set and predict on the validation set.\n",
    "- For each estimator's predictions, print the confusion matrix generated with `confusion_matrix()` by passing both `y_val` and `y_pred`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing confusion matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation sample\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=253\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimensions:  (5455, 95)\n",
      "y_train dimensions:  (5455,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train dimensions: ', X_train.shape)\n",
    "print('y_train dimensions: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_val dimensions:  (1364, 95)\n",
      "y_val dimensions:  (1364,)\n"
     ]
    }
   ],
   "source": [
    "print('X_val dimensions: ', X_val.shape)\n",
    "print('y_val dimensions: ', y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Confusion Matrix:\n",
      "[[1301   15]\n",
      " [  39    9]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict KNN pipeline\n",
    "\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "y_pred = knn_pipe.predict(X_val)\n",
    "cfm=confusion_matrix(y_val.tolist(),y_pred.tolist())\n",
    "print('KNN Confusion Matrix:')\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Confusion Matrix:\n",
      "[[1315    1]\n",
      " [  47    1]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict SVM pipeline\n",
    "SVC_pipe.fit(X_train, y_train)\n",
    "y_pred = SVC_pipe.predict(X_val)\n",
    "cfm=confusion_matrix(y_val.tolist(),y_pred.tolist())\n",
    "print('SVM Confusion Matrix:')\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Confusion Matrix:\n",
      "[[1307    9]\n",
      " [  39    9]]\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict Logistic Regression pipeline\n",
    "logit_pipe.fit(X_train, y_train)\n",
    "y_pred = logit_pipe.predict(X_val)\n",
    "cfm=confusion_matrix(y_val.tolist(),y_pred.tolist())\n",
    "print('Logit Confusion Matrix:')\n",
    "print(cfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our confusion matrix, we can then derive the following useful metrics:\n",
    "\n",
    "\n",
    "$$\\text{Precision} = \\frac{TP}{TP+FP} \\\\\n",
    "\\text{Recall} = \\frac{TP}{TP+FN}\\\\\n",
    "\\text{F1 Score} = 2 * \\frac{\\text{Precision} * \\text{Recall}}{\\text{Precision} + \\text{Recall}}$$\n",
    "\n",
    "\n",
    "One way to obtain all of these metrics is using the `classification_report()` function from scikit learn (for documentation, see [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification#sklearn.metrics.classification_report)). Try outputting the classification report for our three models below:\n",
    "\n",
    "- Import the `classification_report()` function from scikit learn.\n",
    "- Fit all pipeline estimators on the training set and predict on the validation set.\n",
    "- For each estimator's predictions, print the confusion matrix generated with `classification_report()` by passing both `y_val` and `y_pred`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing classification_report\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1316\n",
      "           1       0.38      0.19      0.25        48\n",
      "\n",
      "    accuracy                           0.96      1364\n",
      "   macro avg       0.67      0.59      0.61      1364\n",
      "weighted avg       0.95      0.96      0.95      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict KNN pipeline\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "y_pred = knn_pipe.predict(X_val)\n",
    "print('KNN Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      1316\n",
      "           1       0.50      0.02      0.04        48\n",
      "\n",
      "    accuracy                           0.96      1364\n",
      "   macro avg       0.73      0.51      0.51      1364\n",
      "weighted avg       0.95      0.96      0.95      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict SVM pipeline\n",
    "SVC_pipe.fit(X_train, y_train)\n",
    "y_pred = SVC_pipe.predict(X_val)\n",
    "print('SVC Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      1316\n",
      "           1       0.50      0.15      0.23        48\n",
      "\n",
      "    accuracy                           0.96      1364\n",
      "   macro avg       0.73      0.57      0.60      1364\n",
      "weighted avg       0.95      0.96      0.96      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict Logistic Regression pipeline\n",
    "logit_pipe.fit(X_train, y_train)\n",
    "y_pred = logit_pipe.predict(X_val)\n",
    "print('Logit Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class imbalance and resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from our classification reports, one metric that is especially low for all three models is recall amongst bankrupt companies. This highlights a frequent problem in classification ML which is known as **class imbalance**. It occurs when one class is significantly underrepresented in the training data, and thus our models are trained really well at \"spotting\" the majority class (which is easy), but really bad at spotting the minority one. This is problematic as our interest is often to predict the minority class (i.e bankrupt companies).\n",
    "\n",
    "To illustrate imbalance in our training data set, have a look at the plot below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ploting class imbalance\n",
    "fig, ax = plt.subplots(figsize=(6, 6)) \n",
    "ax.bar([0,1],y_train.value_counts())\n",
    "ax.set_xlabel('Bankrupt')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_title('Distribution of company bankruptcy ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve our model's ability to pick up bankrupt companies, we must resample our data set. There are generally two ways to do this:\n",
    "- Undersampling the majority class.\n",
    "- Oversampling the minority class.\n",
    "\n",
    "Here, we'll take a look at the latter option using a technique called Synthetic Minority Over-sampling Technique (SMOTE). For a more in depth treatment of this technique please refer [here](https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/).\n",
    "\n",
    "To apply SMOTE, we'll have to use another library called Imbalanced Learn (imported as `imblearn`). To start, lets see how SMOTE resampling changes our class distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SMOTE class from Imbalanced Learn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resampling data\n",
    "sm = SMOTE(random_state=243)\n",
    "X_res, y_res = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Re-plotting class balance\n",
    "fig, ax = plt.subplots(figsize=(6, 6)) \n",
    "ax.bar([0,1],y_res.value_counts())\n",
    "ax.set_xlabel('Bankrupt')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xticks([0,1])\n",
    "ax.set_title('Distribution of company bankruptcy ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is great about this library is that it is built to integrate with scikit learn, so we can just add the SMOTE transformer onto our Pipelines. The only caveat is that, to do this, we must import the `make_pipeline()` function from Imbalanced Learn (for documentation, see [here](https://imbalanced-learn.org/stable/references/generated/imblearn.pipeline.make_pipeline.html)). Have a go at changing our Pipelines (add SMOTE resampling as the first step) and then use these to predict on our validation samples:\n",
    "- Import the `make_pipeline()` function from imblearn.\n",
    "- Make a pipeline for each estimator by passing the following transformers (in order): SMOTE, Scaling, PCA, estimator.\n",
    "- Fit on the training set and predict on the validation set using all three pipelines.\n",
    "- Print out the classification report for all three models. \n",
    "\n",
    "> **Note:** The `.make_pipeline()` function, unlike the method `Pipeline()`, does not require a list of tuples as an argument. Instead, just pass in whatever transformers and estimators you want in order (separated by commas.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing make_pipeline\n",
    "from imblearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three Pipelines, one for each model\n",
    "knn_pipe = make_pipeline(SMOTE(random_state=253), StandardScaler(), PCA(n_components=30), KNeighborsClassifier())\n",
    "SVC_pipe = make_pipeline(SMOTE(random_state=253), StandardScaler(), PCA(n_components=30), SVC())\n",
    "logit_pipe = make_pipeline(SMOTE(random_state=253), StandardScaler(), PCA(n_components=30), LogisticRegression()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict KNN pipeline\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "y_pred = knn_pipe.predict(X_val)\n",
    "print('KNN Classification Report:')\n",
    "print(classification_report(y_val, y_pred))\n",
    "print('KNN Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      1316\n",
      "           1       0.20      0.69      0.31        48\n",
      "\n",
      "    accuracy                           0.89      1364\n",
      "   macro avg       0.59      0.79      0.63      1364\n",
      "weighted avg       0.96      0.89      0.92      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict SVM pipeline\n",
    "SVC_pipe.fit(X_train, y_train)\n",
    "y_pred = SVC_pipe.predict(X_val)\n",
    "print('SVC Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logit Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.87      0.93      1316\n",
      "           1       0.19      0.85      0.31        48\n",
      "\n",
      "    accuracy                           0.87      1364\n",
      "   macro avg       0.59      0.86      0.62      1364\n",
      "weighted avg       0.97      0.87      0.91      1364\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict Logistic Regression pipeline\n",
    "logit_pipe.fit(X_train, y_train)\n",
    "y_pred = logit_pipe.predict(X_val)\n",
    "print('Logit Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping it all up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're nearly there! Now its time to train our models using the whole initial training set (training + validation) to then predict on the test set:\n",
    "- Merge the training and validation sets into a new training set (covered in previous sessions).\n",
    "- Fit each model on the new training set.\n",
    "- Predict with each model on the test set.\n",
    "- Print out the classification report of your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g1/7qhqkzx5133glbzkt6wybybh0000gn/T/ipykernel_34981/2541278675.py:2: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  X_train = X_train.append(X_val, ignore_index=True)\n",
      "/var/folders/g1/7qhqkzx5133glbzkt6wybybh0000gn/T/ipykernel_34981/2541278675.py:3: FutureWarning: The series.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  y_train = y_train.append(y_val, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# Merging together training and validation samples\n",
    "X_train = X_train.append(X_val, ignore_index=True)\n",
    "y_train = y_train.append(y_val, ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimensions:  (6819, 95)\n",
      "y_train dimensions:  (6819,)\n"
     ]
    }
   ],
   "source": [
    "print('X_train dimensions: ', X_train.shape)\n",
    "print('y_train dimensions: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95      1981\n",
      "           1       0.27      1.00      0.42        65\n",
      "\n",
      "    accuracy                           0.91      2046\n",
      "   macro avg       0.63      0.96      0.69      2046\n",
      "weighted avg       0.98      0.91      0.94      2046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict KNN pipeline\n",
    "knn_pipe.fit(X_train, y_train)\n",
    "y_pred = knn_pipe.predict(X_test)\n",
    "print('KNN Classification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and predict SVM pipeline\n",
    "SVC_pipe.fit(X_train, y_train)\n",
    "y_pred = SVC_pipe.predict(X_val)\n",
    "print('SVC Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fit and predict Logistic Regression pipeline\n",
    "logit_pipe.fit(X_train, y_train)\n",
    "y_pred = logit_pipe.predict(X_val)\n",
    "print('Logit Classification Report:')\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking it up a notch\n",
    "With this, we come to the end of this project, although this does not mean that you're done by any means. The project explored today can be improved in many ways to achieve better results, and doing so is what will truly help you grow as a data scientist. Here are some suggestions for improvements to this particular project:\n",
    "- **EDA:**\n",
    "    - How are the features in our data set distributed?\n",
    "    - What is the individual relationship of each of these with our target variable?\n",
    "    \n",
    "    \n",
    "- **Dimentionality reduction:**\n",
    "    - What number of components should we use to improve our predictions?\n",
    "    - What other dimensionality reduction techniques are there? (Hint: have a look at manifold learning models like [tSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)) \n",
    "    \n",
    "    \n",
    "- **Preprocessing:**\n",
    "    - What other scaling methods are there? Which is the best for this problem?\n",
    "    - Is there any feature engineering that we can do? How?\n",
    "    - How do other resampling methods affect performance?\n",
    "    \n",
    "    \n",
    "- **Modelling:**\n",
    "    - What other classification models can you use?\n",
    "    - Try out ensemble models: random forests, LightGBM XGBoost... which works out best?\n",
    "    - Can you optimize any hyperparameters? How?\n",
    "    \n",
    "- **Evaluation Metrics:**\n",
    "    - Try looking at the ROC curve and the associated AUC metric [(link here)](https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5). Can you implement these in your project? \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression: What are the drivers of worker productivity?\n",
    "For this project, we will aim to predict the level of productivity for workers in the garment industry given a variety of production and supply chain metrics. To do this, we will use  data collected from January to March 2015 by the Industrial Engineering (IE) department of a garment manufacturing unit in\n",
    "Bangladesh. This kind of model would have all sorts of real world applications within the fields of operational research, labour economics, and supply chain management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start out, lets get an overview of our data set dimensions and feature types. We'll be doing a very simple overview in this section but feel free to perform more extensive EDA on your own: the more you know about your data, the better you can harness it through modelling.\n",
    "\n",
    "Start out with the following tasks:\n",
    "- Read in the data set as a pandas DataFrame (file path: `data/garments_worker_productivity.csv'`)\n",
    "- Output the first ten data set rows\n",
    "- Output the last ten data set rows\n",
    "- Print out a comprehensive summary of the data set (dimensions, variable names, data types, and null values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read bankruptcy data set\n",
    "df = pd.read_csv(\"garments_worker_productivity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>quarter</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>targeted_productivity</th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>idle_time</th>\n",
       "      <th>idle_men</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "      <th>actual_productivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>26.16</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>7080</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.940725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.886500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.800570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>12</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.800570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>25.90</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.800382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>7</td>\n",
       "      <td>0.80</td>\n",
       "      <td>25.90</td>\n",
       "      <td>984.0</td>\n",
       "      <td>6720</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.800125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.755167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>28.08</td>\n",
       "      <td>795.0</td>\n",
       "      <td>6900</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.753683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>19.87</td>\n",
       "      <td>733.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.753098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>28.08</td>\n",
       "      <td>681.0</td>\n",
       "      <td>6900</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.750428</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date   quarter  department       day  team  targeted_productivity  \\\n",
       "0  1/1/2015  Quarter1      sweing  Thursday     8                   0.80   \n",
       "1  1/1/2015  Quarter1  finishing   Thursday     1                   0.75   \n",
       "2  1/1/2015  Quarter1      sweing  Thursday    11                   0.80   \n",
       "3  1/1/2015  Quarter1      sweing  Thursday    12                   0.80   \n",
       "4  1/1/2015  Quarter1      sweing  Thursday     6                   0.80   \n",
       "5  1/1/2015  Quarter1      sweing  Thursday     7                   0.80   \n",
       "6  1/1/2015  Quarter1  finishing   Thursday     2                   0.75   \n",
       "7  1/1/2015  Quarter1      sweing  Thursday     3                   0.75   \n",
       "8  1/1/2015  Quarter1      sweing  Thursday     2                   0.75   \n",
       "9  1/1/2015  Quarter1      sweing  Thursday     1                   0.75   \n",
       "\n",
       "     smv     wip  over_time  incentive  idle_time  idle_men  \\\n",
       "0  26.16  1108.0       7080         98        0.0         0   \n",
       "1   3.94     NaN        960          0        0.0         0   \n",
       "2  11.41   968.0       3660         50        0.0         0   \n",
       "3  11.41   968.0       3660         50        0.0         0   \n",
       "4  25.90  1170.0       1920         50        0.0         0   \n",
       "5  25.90   984.0       6720         38        0.0         0   \n",
       "6   3.94     NaN        960          0        0.0         0   \n",
       "7  28.08   795.0       6900         45        0.0         0   \n",
       "8  19.87   733.0       6000         34        0.0         0   \n",
       "9  28.08   681.0       6900         45        0.0         0   \n",
       "\n",
       "   no_of_style_change  no_of_workers  actual_productivity  \n",
       "0                   0           59.0             0.940725  \n",
       "1                   0            8.0             0.886500  \n",
       "2                   0           30.5             0.800570  \n",
       "3                   0           30.5             0.800570  \n",
       "4                   0           56.0             0.800382  \n",
       "5                   0           56.0             0.800125  \n",
       "6                   0            8.0             0.755167  \n",
       "7                   0           57.5             0.753683  \n",
       "8                   0           55.0             0.753098  \n",
       "9                   0           57.5             0.750428  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the first ten rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the last ten rows\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1197 entries, 0 to 1196\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   date                   1197 non-null   object \n",
      " 1   quarter                1197 non-null   object \n",
      " 2   department             1197 non-null   object \n",
      " 3   day                    1197 non-null   object \n",
      " 4   team                   1197 non-null   int64  \n",
      " 5   targeted_productivity  1197 non-null   float64\n",
      " 6   smv                    1197 non-null   float64\n",
      " 7   wip                    691 non-null    float64\n",
      " 8   over_time              1197 non-null   int64  \n",
      " 9   incentive              1197 non-null   int64  \n",
      " 10  idle_time              1197 non-null   float64\n",
      " 11  idle_men               1197 non-null   int64  \n",
      " 12  no_of_style_change     1197 non-null   int64  \n",
      " 13  no_of_workers          1197 non-null   float64\n",
      " 14  actual_productivity    1197 non-null   float64\n",
      "dtypes: float64(6), int64(5), object(4)\n",
      "memory usage: 140.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print the data set overview (dimensions, variable names, data types, null values)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering with dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the features in our data set provides date information. In this format, the feature can be quite useless, but there are several things that we can do to extract useful information from it relating to worker productivity. To start, we want to convert the feature entries into `datetime` objects. To do this:\n",
    "- Use the `pd.to_datetime()` function to reset the `'date'` column in our data set.\n",
    "> **Note:** In order to get the right format, pass the argument `format = '%m/%d/%Y' `, and have a read [here](https://www.w3schools.com/python/python_datetime.asp) for further information on how to handle datetime objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 'date' column into datetime \n",
    "df['date']=pd.to_datetime(df['date'],format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With our 'date' column in `datetime` format, we can now proceed to extract a number of additional features. Although you can find the full list of `datetime` attributes [here](https://pandas.pydata.org/pandas-docs/version/0.23/api.html#datetimelike-properties), we will focus on extracting the day of the week and the month as separate features. To extract a `datetime` attribute as a feature, we can use the following command:\n",
    "- `data['<new_feature_label>'] = data['date'].dt.<attribute>`\n",
    "\n",
    "Try extracting the attributes `.month` and `.dayofweek` and assigning it to columns with the labels `'month'` and `'day'` respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>quarter</th>\n",
       "      <th>department</th>\n",
       "      <th>day</th>\n",
       "      <th>team</th>\n",
       "      <th>targeted_productivity</th>\n",
       "      <th>smv</th>\n",
       "      <th>wip</th>\n",
       "      <th>over_time</th>\n",
       "      <th>incentive</th>\n",
       "      <th>idle_time</th>\n",
       "      <th>idle_men</th>\n",
       "      <th>no_of_style_change</th>\n",
       "      <th>no_of_workers</th>\n",
       "      <th>actual_productivity</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.80</td>\n",
       "      <td>26.16</td>\n",
       "      <td>1108.0</td>\n",
       "      <td>7080</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.940725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.886500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.800570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>968.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.800570</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.80</td>\n",
       "      <td>25.90</td>\n",
       "      <td>1170.0</td>\n",
       "      <td>1920</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.800382</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.80</td>\n",
       "      <td>25.90</td>\n",
       "      <td>984.0</td>\n",
       "      <td>6720</td>\n",
       "      <td>38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.800125</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.755167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>28.08</td>\n",
       "      <td>795.0</td>\n",
       "      <td>6900</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.753683</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>19.87</td>\n",
       "      <td>733.0</td>\n",
       "      <td>6000</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.753098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>28.08</td>\n",
       "      <td>681.0</td>\n",
       "      <td>6900</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.750428</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.70</td>\n",
       "      <td>28.08</td>\n",
       "      <td>872.0</td>\n",
       "      <td>6900</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.5</td>\n",
       "      <td>0.721127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>19.31</td>\n",
       "      <td>578.0</td>\n",
       "      <td>6480</td>\n",
       "      <td>45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.712205</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.80</td>\n",
       "      <td>11.41</td>\n",
       "      <td>668.0</td>\n",
       "      <td>3660</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.707046</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.65</td>\n",
       "      <td>3.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.705917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2160</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.593056</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.80</td>\n",
       "      <td>2.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.540729</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.65</td>\n",
       "      <td>23.69</td>\n",
       "      <td>861.0</td>\n",
       "      <td>7200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.521180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.70</td>\n",
       "      <td>4.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.436326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6600</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.988025</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0.75</td>\n",
       "      <td>2.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5640</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.987880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>0.80</td>\n",
       "      <td>4.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.956271</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.945278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>finishing</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>3.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>960</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.902917</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2015-01-03</td>\n",
       "      <td>Quarter1</td>\n",
       "      <td>sweing</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>28.08</td>\n",
       "      <td>772.0</td>\n",
       "      <td>6300</td>\n",
       "      <td>50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56.5</td>\n",
       "      <td>0.800725</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   quarter  department  day  team  targeted_productivity    smv  \\\n",
       "0  2015-01-01  Quarter1      sweing    1     8                   0.80  26.16   \n",
       "1  2015-01-01  Quarter1  finishing     1     1                   0.75   3.94   \n",
       "2  2015-01-01  Quarter1      sweing    1    11                   0.80  11.41   \n",
       "3  2015-01-01  Quarter1      sweing    1    12                   0.80  11.41   \n",
       "4  2015-01-01  Quarter1      sweing    1     6                   0.80  25.90   \n",
       "5  2015-01-01  Quarter1      sweing    1     7                   0.80  25.90   \n",
       "6  2015-01-01  Quarter1  finishing     1     2                   0.75   3.94   \n",
       "7  2015-01-01  Quarter1      sweing    1     3                   0.75  28.08   \n",
       "8  2015-01-01  Quarter1      sweing    1     2                   0.75  19.87   \n",
       "9  2015-01-01  Quarter1      sweing    1     1                   0.75  28.08   \n",
       "10 2015-01-01  Quarter1      sweing    1     9                   0.70  28.08   \n",
       "11 2015-01-01  Quarter1      sweing    1    10                   0.75  19.31   \n",
       "12 2015-01-01  Quarter1      sweing    1     5                   0.80  11.41   \n",
       "13 2015-01-01  Quarter1  finishing     1    10                   0.65   3.94   \n",
       "14 2015-01-01  Quarter1  finishing     1     8                   0.75   2.90   \n",
       "15 2015-01-01  Quarter1  finishing     1     4                   0.75   3.94   \n",
       "16 2015-01-01  Quarter1  finishing     1     7                   0.80   2.90   \n",
       "17 2015-01-01  Quarter1      sweing    1     4                   0.65  23.69   \n",
       "18 2015-01-01  Quarter1   finishing    1    11                   0.70   4.15   \n",
       "19 2015-01-03  Quarter1  finishing     3     4                   0.80   4.15   \n",
       "20 2015-01-03  Quarter1  finishing     3    11                   0.75   2.90   \n",
       "21 2015-01-03  Quarter1  finishing     3     9                   0.80   4.15   \n",
       "22 2015-01-03  Quarter1  finishing     3     3                   0.75   3.94   \n",
       "23 2015-01-03  Quarter1  finishing     3     1                   0.80   3.94   \n",
       "24 2015-01-03  Quarter1      sweing    3     1                   0.80  28.08   \n",
       "\n",
       "       wip  over_time  incentive  idle_time  idle_men  no_of_style_change  \\\n",
       "0   1108.0       7080         98        0.0         0                   0   \n",
       "1      NaN        960          0        0.0         0                   0   \n",
       "2    968.0       3660         50        0.0         0                   0   \n",
       "3    968.0       3660         50        0.0         0                   0   \n",
       "4   1170.0       1920         50        0.0         0                   0   \n",
       "5    984.0       6720         38        0.0         0                   0   \n",
       "6      NaN        960          0        0.0         0                   0   \n",
       "7    795.0       6900         45        0.0         0                   0   \n",
       "8    733.0       6000         34        0.0         0                   0   \n",
       "9    681.0       6900         45        0.0         0                   0   \n",
       "10   872.0       6900         44        0.0         0                   0   \n",
       "11   578.0       6480         45        0.0         0                   0   \n",
       "12   668.0       3660         50        0.0         0                   0   \n",
       "13     NaN        960          0        0.0         0                   0   \n",
       "14     NaN        960          0        0.0         0                   0   \n",
       "15     NaN       2160          0        0.0         0                   0   \n",
       "16     NaN        960          0        0.0         0                   0   \n",
       "17   861.0       7200          0        0.0         0                   0   \n",
       "18     NaN       1440          0        0.0         0                   0   \n",
       "19     NaN       6600          0        0.0         0                   0   \n",
       "20     NaN       5640          0        0.0         0                   0   \n",
       "21     NaN        960          0        0.0         0                   0   \n",
       "22     NaN       1560          0        0.0         0                   0   \n",
       "23     NaN        960          0        0.0         0                   0   \n",
       "24   772.0       6300         50        0.0         0                   0   \n",
       "\n",
       "    no_of_workers  actual_productivity  month  \n",
       "0            59.0             0.940725      1  \n",
       "1             8.0             0.886500      1  \n",
       "2            30.5             0.800570      1  \n",
       "3            30.5             0.800570      1  \n",
       "4            56.0             0.800382      1  \n",
       "5            56.0             0.800125      1  \n",
       "6             8.0             0.755167      1  \n",
       "7            57.5             0.753683      1  \n",
       "8            55.0             0.753098      1  \n",
       "9            57.5             0.750428      1  \n",
       "10           57.5             0.721127      1  \n",
       "11           54.0             0.712205      1  \n",
       "12           30.5             0.707046      1  \n",
       "13            8.0             0.705917      1  \n",
       "14            8.0             0.676667      1  \n",
       "15           18.0             0.593056      1  \n",
       "16            8.0             0.540729      1  \n",
       "17           60.0             0.521180      1  \n",
       "18           12.0             0.436326      1  \n",
       "19           20.0             0.988025      1  \n",
       "20           17.0             0.987880      1  \n",
       "21            8.0             0.956271      1  \n",
       "22            8.0             0.945278      1  \n",
       "23            8.0             0.902917      1  \n",
       "24           56.5             0.800725      1  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating month and day of the week features\n",
    "df['month']=df['date'].dt.month\n",
    "df['day']=df['date'].dt.day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we want to drop the `'date'` feature from our data set (as this can be hard to encode) and output the first ten rows of our data set and the data set overview to check the new features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping 'date' column\n",
    "df = df.drop(columns='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the first ten rows\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1197 entries, 0 to 1196\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   quarter                1197 non-null   object \n",
      " 1   department             1197 non-null   object \n",
      " 2   day                    1197 non-null   int64  \n",
      " 3   team                   1197 non-null   int64  \n",
      " 4   targeted_productivity  1197 non-null   float64\n",
      " 5   smv                    1197 non-null   float64\n",
      " 6   wip                    691 non-null    float64\n",
      " 7   over_time              1197 non-null   int64  \n",
      " 8   incentive              1197 non-null   int64  \n",
      " 9   idle_time              1197 non-null   float64\n",
      " 10  idle_men               1197 non-null   int64  \n",
      " 11  no_of_style_change     1197 non-null   int64  \n",
      " 12  no_of_workers          1197 non-null   float64\n",
      " 13  actual_productivity    1197 non-null   float64\n",
      " 14  month                  1197 non-null   int64  \n",
      "dtypes: float64(6), int64(7), object(2)\n",
      "memory usage: 140.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# Print the data set overview (dimensions, variable names, data types, null values)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've extracted some new features from our date data, we want to encode all our features so that they're ready for machine learning modeling. This includes encoding all of our categorical features as 'dummy variables'. Whilst this may seem easy at first sight, check the unique values (using `.unique()`) for the following features: `'team'`, `'month'`, `'day'`. Do these seem like continuous or categorical variables to you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  1, 11, 12,  6,  7,  2,  3,  9, 10,  5,  4])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values for 'team'\n",
    "df['team'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values for 'month' \n",
    "df['month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20,\n",
       "       21, 22, 24, 25, 26, 27, 28, 29, 31,  2,  9, 16, 23])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking unique values for 'day' \n",
    "df['day'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, these features, although of numerical data type, fall much better under the definition of categorical variables. Had we not noticed, they would not get dummy encoded by the `pd.get_dummies()` function, leading to the incorrect handling of our data. Thus, its important to always check what kind of features we have, irrespective if data type. We can get around this encoding problem by casting these features as `str` types and then proceeding with the dummy encoding. In our data set:\n",
    "- Cast the features `'team'`, `'month'`, and `'day'` as strings.\n",
    "- Use the `pd.get_dummies()` function to dummy encode categorical variables (Hint: remember to drop one dummy pre categorical feature using the `drop_first` parameter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast 'team', 'month', and 'day' features as str\n",
    "df['team'] = df['team'].astype(str)\n",
    "df['month']=df['month'].astype(str)\n",
    "df['day']=df['day'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate dummy encoding\n",
    "df = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1197 entries, 0 to 1196\n",
      "Data columns (total 58 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   targeted_productivity  1197 non-null   float64\n",
      " 1   smv                    1197 non-null   float64\n",
      " 2   wip                    691 non-null    float64\n",
      " 3   over_time              1197 non-null   int64  \n",
      " 4   incentive              1197 non-null   int64  \n",
      " 5   idle_time              1197 non-null   float64\n",
      " 6   idle_men               1197 non-null   int64  \n",
      " 7   no_of_style_change     1197 non-null   int64  \n",
      " 8   no_of_workers          1197 non-null   float64\n",
      " 9   actual_productivity    1197 non-null   float64\n",
      " 10  quarter_Quarter2       1197 non-null   uint8  \n",
      " 11  quarter_Quarter3       1197 non-null   uint8  \n",
      " 12  quarter_Quarter4       1197 non-null   uint8  \n",
      " 13  quarter_Quarter5       1197 non-null   uint8  \n",
      " 14  department_finishing   1197 non-null   uint8  \n",
      " 15  department_sweing      1197 non-null   uint8  \n",
      " 16  day_10                 1197 non-null   uint8  \n",
      " 17  day_11                 1197 non-null   uint8  \n",
      " 18  day_12                 1197 non-null   uint8  \n",
      " 19  day_13                 1197 non-null   uint8  \n",
      " 20  day_14                 1197 non-null   uint8  \n",
      " 21  day_15                 1197 non-null   uint8  \n",
      " 22  day_16                 1197 non-null   uint8  \n",
      " 23  day_17                 1197 non-null   uint8  \n",
      " 24  day_18                 1197 non-null   uint8  \n",
      " 25  day_19                 1197 non-null   uint8  \n",
      " 26  day_2                  1197 non-null   uint8  \n",
      " 27  day_20                 1197 non-null   uint8  \n",
      " 28  day_21                 1197 non-null   uint8  \n",
      " 29  day_22                 1197 non-null   uint8  \n",
      " 30  day_23                 1197 non-null   uint8  \n",
      " 31  day_24                 1197 non-null   uint8  \n",
      " 32  day_25                 1197 non-null   uint8  \n",
      " 33  day_26                 1197 non-null   uint8  \n",
      " 34  day_27                 1197 non-null   uint8  \n",
      " 35  day_28                 1197 non-null   uint8  \n",
      " 36  day_29                 1197 non-null   uint8  \n",
      " 37  day_3                  1197 non-null   uint8  \n",
      " 38  day_31                 1197 non-null   uint8  \n",
      " 39  day_4                  1197 non-null   uint8  \n",
      " 40  day_5                  1197 non-null   uint8  \n",
      " 41  day_6                  1197 non-null   uint8  \n",
      " 42  day_7                  1197 non-null   uint8  \n",
      " 43  day_8                  1197 non-null   uint8  \n",
      " 44  day_9                  1197 non-null   uint8  \n",
      " 45  team_10                1197 non-null   uint8  \n",
      " 46  team_11                1197 non-null   uint8  \n",
      " 47  team_12                1197 non-null   uint8  \n",
      " 48  team_2                 1197 non-null   uint8  \n",
      " 49  team_3                 1197 non-null   uint8  \n",
      " 50  team_4                 1197 non-null   uint8  \n",
      " 51  team_5                 1197 non-null   uint8  \n",
      " 52  team_6                 1197 non-null   uint8  \n",
      " 53  team_7                 1197 non-null   uint8  \n",
      " 54  team_8                 1197 non-null   uint8  \n",
      " 55  team_9                 1197 non-null   uint8  \n",
      " 56  month_2                1197 non-null   uint8  \n",
      " 57  month_3                1197 non-null   uint8  \n",
      "dtypes: float64(6), int64(4), uint8(48)\n",
      "memory usage: 149.8 KB\n"
     ]
    }
   ],
   "source": [
    "# Print data set overview\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our ML setup\n",
    "Now that we have our variables encoded we want to set up our data in the usual machine learning configuration: a training and a test set, each with a feature matrix and a target vector. To start:\n",
    "\n",
    "- Import the `train_test_split()` function from scikit learn\n",
    "- Declare a target vector y (corresponding to the `actual_productivity` column in the data set)\n",
    "- Declare a feature matrix X (including all columns except `actual_productivity`)\n",
    "- Create a training and test set\n",
    "- Print the dimensions of X and y in both the training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing train-test split function\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare the training vector y which has the column label 'actual_productivity'\n",
    "y = df.actual_productivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare feature matrix \n",
    "X=df.drop('actual_productivity',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train-test- split using random state 253, test_size 30%\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y, test_size=0.3, random_state=253) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimensions:  (837, 57)\n",
      "y_train dimensions:  (837,)\n"
     ]
    }
   ],
   "source": [
    "# Print dimensions of the training set\n",
    "print('X_train dimensions: ', X_train.shape)\n",
    "print('y_train dimensions: ', y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test dimensions:  (360, 57)\n",
      "y_test dimensions:  (360,)\n"
     ]
    }
   ],
   "source": [
    "# Print dimensions of the test set\n",
    "print('X_test dimensions: ', X_test.shape)\n",
    "print('y_test dimensions: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you probably already noticed, we have several missing values in the `'wip'` column of our data set. This time, however, we will use a more advanced method to impute missing values. More specifically, we will use the K Nearest Neighbors algorithm to impute values that are similar to other nearby samples, which should hopefully give us more accuracy. To do this:\n",
    "- Import the `KNNImputer` class from scikit learn\n",
    "- Create `KNNImputer` transformer, passing `n_neighbors=7` as an argument.\n",
    "- Fit the transformer using `X_train`\n",
    "- Impute missing values by calling the `.transform()` method with `X_train` as an argument. Assign this to a new variable `X_full`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KNNImputer\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating KNNImputer transformer\n",
    "imputer = KNNImputer(n_neighbors=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 837 entries, 1116 to 779\n",
      "Data columns (total 57 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   targeted_productivity  837 non-null    float64\n",
      " 1   smv                    837 non-null    float64\n",
      " 2   wip                    485 non-null    float64\n",
      " 3   over_time              837 non-null    int64  \n",
      " 4   incentive              837 non-null    int64  \n",
      " 5   idle_time              837 non-null    float64\n",
      " 6   idle_men               837 non-null    int64  \n",
      " 7   no_of_style_change     837 non-null    int64  \n",
      " 8   no_of_workers          837 non-null    float64\n",
      " 9   quarter_Quarter2       837 non-null    uint8  \n",
      " 10  quarter_Quarter3       837 non-null    uint8  \n",
      " 11  quarter_Quarter4       837 non-null    uint8  \n",
      " 12  quarter_Quarter5       837 non-null    uint8  \n",
      " 13  department_finishing   837 non-null    uint8  \n",
      " 14  department_sweing      837 non-null    uint8  \n",
      " 15  day_10                 837 non-null    uint8  \n",
      " 16  day_11                 837 non-null    uint8  \n",
      " 17  day_12                 837 non-null    uint8  \n",
      " 18  day_13                 837 non-null    uint8  \n",
      " 19  day_14                 837 non-null    uint8  \n",
      " 20  day_15                 837 non-null    uint8  \n",
      " 21  day_16                 837 non-null    uint8  \n",
      " 22  day_17                 837 non-null    uint8  \n",
      " 23  day_18                 837 non-null    uint8  \n",
      " 24  day_19                 837 non-null    uint8  \n",
      " 25  day_2                  837 non-null    uint8  \n",
      " 26  day_20                 837 non-null    uint8  \n",
      " 27  day_21                 837 non-null    uint8  \n",
      " 28  day_22                 837 non-null    uint8  \n",
      " 29  day_23                 837 non-null    uint8  \n",
      " 30  day_24                 837 non-null    uint8  \n",
      " 31  day_25                 837 non-null    uint8  \n",
      " 32  day_26                 837 non-null    uint8  \n",
      " 33  day_27                 837 non-null    uint8  \n",
      " 34  day_28                 837 non-null    uint8  \n",
      " 35  day_29                 837 non-null    uint8  \n",
      " 36  day_3                  837 non-null    uint8  \n",
      " 37  day_31                 837 non-null    uint8  \n",
      " 38  day_4                  837 non-null    uint8  \n",
      " 39  day_5                  837 non-null    uint8  \n",
      " 40  day_6                  837 non-null    uint8  \n",
      " 41  day_7                  837 non-null    uint8  \n",
      " 42  day_8                  837 non-null    uint8  \n",
      " 43  day_9                  837 non-null    uint8  \n",
      " 44  team_10                837 non-null    uint8  \n",
      " 45  team_11                837 non-null    uint8  \n",
      " 46  team_12                837 non-null    uint8  \n",
      " 47  team_2                 837 non-null    uint8  \n",
      " 48  team_3                 837 non-null    uint8  \n",
      " 49  team_4                 837 non-null    uint8  \n",
      " 50  team_5                 837 non-null    uint8  \n",
      " 51  team_6                 837 non-null    uint8  \n",
      " 52  team_7                 837 non-null    uint8  \n",
      " 53  team_8                 837 non-null    uint8  \n",
      " 54  team_9                 837 non-null    uint8  \n",
      " 55  month_2                837 non-null    uint8  \n",
      " 56  month_3                837 non-null    uint8  \n",
      "dtypes: float64(5), int64(4), uint8(48)\n",
      "memory usage: 104.6 KB\n"
     ]
    }
   ],
   "source": [
    "# Fitting and transforming training feature matrix using our imputer\n",
    "X_train.info()\n",
    "imputer.fit(X_train)\n",
    "X_full = imputer.transform(X_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might've noticed that most machine learning with scikit learn involves:\n",
    "- Instantiating a transformer or model.\n",
    "- Fitting this to our data using `.fit()`.\n",
    "- Transforming or predicting using `.transform()` or `.predict()`.\n",
    "\n",
    "This simple, general process means that we can simplify our ML process using **Pipelines**. A Pipeline allows you to establish a sequence of transformations terminating with *one estimator*. Pipelines can then be treated as any other scikit learn estimator, but each time they perform all of the interim transformation steps in the sequence. This has the benefit of greatly simplifying your code and can also help prevent [data leakage](https://machinelearningmastery.com/data-leakage-machine-learning/). \n",
    "\n",
    "To instantiate a Pipeline you must pass as an argument a list of $n+1$ tuples (where $n$ is the number of transforms) in the form: `[('transformer_1_name', transformer_1), ..., ('estimator_name', estimator)]`.\n",
    "\n",
    "We will now create Pipelines for both an SVM and a Linear Regression model below:\n",
    "- Import the `StandardScaler`, `SVR`, and `LinearRegression` classes from scikit learn.\n",
    "- Import the `Pipeline` class from scikit learn.\n",
    "- For each one of the two models, create a Pipeline with the following transforms (in order): imputation, scaling, estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing KNN, SVM, and Linear Regression models \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine these into two Pipelines, one for each model\n",
    "lin_reg_pipe = Pipeline([('Imputation', KNNImputer(n_neighbors=7)), \n",
    "                         ('Scaler', StandardScaler()), \n",
    "                         ('Model', LinearRegression())])\n",
    "\n",
    "SVR_pipe= Pipeline([('Imputation', KNNImputer(n_neighbors=7)), \n",
    "                         ('Scaler', StandardScaler()), \n",
    "                         ('Model', SVR())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see how well our models stack up! For regression problems, one metric that is often used to assess model performance is the **Root Mean Squared Error (RMSE)**. this is given by:\n",
    "$$\\text{RMSE}=\\sqrt{\\frac{\\sum_{i=1}^n (\\,y_i\\,-\\,y_i^{pred}\\,)^2}{n}}$$\n",
    "\n",
    "We can compare our models by computing the cross-validated RMSE scores:\n",
    "- Import the `cross_val_score()` function from scikit learn.\n",
    "- Calculate the cross-validated scores for each pipeline estimator. \n",
    "- Print the mean score for each pipeline estimator.\n",
    "> **Note:**  Pass `scoring = 'neg_root_mean_squared_error'` as an argument to `cross_val_score()` to ensure that it computes the RMSE for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the cross-validated score of these two models\n",
    "lin_reg_score=cross_val_score(lin_reg_pipe, X_train, y_train, scoring = 'neg_root_mean_squared_error').mean()\n",
    "svm_score = cross_val_score(SVR_pipe, X_train, y_train, scoring = 'neg_root_mean_squared_error').mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE Score:\n",
      "0.14973998003213967\n"
     ]
    }
   ],
   "source": [
    "print('Linear Regression RMSE Score:')\n",
    "print((-1)*lin_reg_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RMSE Score:\n",
      "0.16035844799949595\n"
     ]
    }
   ],
   "source": [
    "print('SVM RMSE Score:')\n",
    "print((-1)*svm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now learn about a more advanced technique called **regularization** that can help us build better regression models. Regularization is an adaptation on the standard linear regression and essentially works by placing a penalty on the size of the regression coefficients when fitting. This is because large coefficients tend to overfit our model to the training data, so by shrinking them we enable the model to generalize better and improve performance on unseen data. A more detailed description of regularization can be found [here](https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a). \n",
    "\n",
    "We will focus on one particular kind of regularized regression model known as **Ridge regression**. One key aspect of ridge regression is the `alpha` hyperparameter, which is used to denote the strength of the penalty on coefficient size. A larger value of`alpha` will seek to shrink coefficients more and viseversa. Finding the optimal `alpha` value can be cumbersome, but luckily we can use the hyperparameter optimization techniques learned in Session Five to do this. \n",
    "\n",
    "Lets try out using a Ridge model for our productivity problem:\n",
    "- Import the `Ridge` and `GridSearchCV` classes from scikit learn\n",
    "- Create a Pipeline with the following transforms (in order): imputation, scaling, Ridge estimator.\n",
    "- Create a `GridSearchCV` object by passing our Ridge pipeline, and the dictionary `params`.\n",
    "- Fit the `GridSearchCV` object using `X_train` and `y_train`.\n",
    "- Print the optimal `alpha` value using the `.best_params_` attribute on our `GridSearchCV` object.\n",
    "- Print the best RMSE score using the `.best_score_` attribute on our `GridSearchCV` object.\n",
    "- Assign the optimized model to `ridge_pipe` using the `.best_estimator_` attribute on our `GridSearchCV` object.\n",
    "> **Note:**  Pass `scoring = 'neg_root_mean_squared_error'` as an argument to `GridSearchCV()` to ensure that it computes the RMSE for our Ridge model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Ridge\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Ridge Pipeline\n",
    "ridge_pipe = Pipeline([('Imputation', KNNImputer(n_neighbors=7)), \n",
    "                       ('Scaler', StandardScaler()), \n",
    "                       ('Model', Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'Model__alpha':np.linspace(0, 1, 40)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Alpha:  {'Model__alpha': 0.02564102564102564}\n",
      "RMSE:  -0.146080649014556\n"
     ]
    }
   ],
   "source": [
    "# Optimizing alpha hyperparameter using GridSearchCV\n",
    "grid_search = GridSearchCV(ridge_pipe,params,scoring='neg_root_mean_squared_error',refit=True)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best Alpha: ', grid_search.best_params_)\n",
    "print('RMSE: ', grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving optimized Ridge model\n",
    "ridge_pipe = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapping it all up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're nearly there! Now its time to train our models using the whole initial training set to then predict on the test set:\n",
    "- Import the `mean_squared_error()` function from scikit learn\n",
    "- Fit each model on the training set.\n",
    "- Predict with each model on the test set.\n",
    "- Print out the RMSE of your predictions using mean_squared_error(). \n",
    "\n",
    "> **Note**: To get the RMSE instead of the MSE, just pass `squared=False` as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression RMSE:\n",
      "0.15597976738507296\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict Linear Regression pipeline\n",
    "lin_reg_pipe.fit(X_train, y_train)\n",
    "y_pred = lin_reg_pipe.predict(X_test)\n",
    "print('Linear Regression RMSE:')\n",
    "print(mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM RMSE:\n",
      "0.15946334752071703\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict SVM pipeline\n",
    "SVR_pipe.fit(X_train, y_train)\n",
    "y_pred = SVR_pipe.predict(X_test)\n",
    "print('SVM RMSE:')\n",
    "print(mean_squared_error(y_test, y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridge RMSE:\n",
      "0.1568620118896236\n"
     ]
    }
   ],
   "source": [
    "# Fit and predict Ridge pipeline\n",
    "ridge_pipe.fit(X_train, y_train)\n",
    "y_pred = ridge_pipe.predict(X_test)\n",
    "print('ridge RMSE:')\n",
    "print(mean_squared_error(y_test, y_pred, squared=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
